import pandas as pd
import numpy as np
import os

# ğŸ“‚ ê²½ë¡œ ì„¤ì • (V1.1 ì¶œë ¥ ê²½ë¡œ)
PROCESSED_PATH = r"C:\Users\ehdwn\Desktop\ì—…ë¡œë“œ í•„ìš”\OneDrive\Study\Fastcamp\ICB6\T_Choi\Procjet1\Brazilian_e-commerce\ê³µí†µë°ì´í„°ì „ì²˜ë¦¬\processed(v1.1)"

errors = []
successes = []

def check(condition, success_msg, error_msg):
    if condition:
        successes.append(success_msg)
    else:
        errors.append(error_msg)

print("="*50)
print("ë¸Œë¼ì§ˆ Olist ë°ì´í„° ì „ì²˜ë¦¬ ê²€ì¦ ì‹œì‘ (V1.1)")
print(f"ëŒ€ìƒ ê²½ë¡œ: {PROCESSED_PATH}")
print("="*50)

if not os.path.exists(PROCESSED_PATH):
    print(f"âŒ ì˜¤ë¥˜: ì¶œë ¥ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ({PROCESSED_PATH})")
    exit()

# 1. olist_orders_dataset.csv ê²€ì¦
print("\n[1/5] ì£¼ë¬¸ ë°ì´í„° ê²€ì¦ ì¤‘...")
orders_file = os.path.join(PROCESSED_PATH, "proc_olist_orders_dataset.csv")
if os.path.exists(orders_file):
    orders = pd.read_csv(orders_file)
    date_cols = ['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']
    
    # íƒ€ì… ê²€ì¦
    for col in date_cols:
        check(pd.api.types.is_datetime64_any_dtype(pd.to_datetime(orders[col], errors='coerce')), 
              f"  - {col}: ë‚ ì§œ í˜•ì‹ í™•ì¸ ì™„ë£Œ", 
              f"  - {col}: ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨")
    
    # íŒŒìƒ ë³€ìˆ˜ ê²€ì¦
    check('actual_delivery_time' in orders.columns, "  - ì‹¤ì œ ë°°ì†¡ ì†Œìš” ì‹œê°„ ì»¬ëŸ¼ ì¡´ì¬", "  - actual_delivery_time ì»¬ëŸ¼ ëˆ„ë½")
    check('delivery_delay_time' in orders.columns, "  - ì˜ˆìƒ ëŒ€ë¹„ ì§€ì—° ì‹œê°„ ì»¬ëŸ¼ ì¡´ì¬", "  - delivery_delay_time ì»¬ëŸ¼ ëˆ„ë½")
else:
    errors.append("proc_olist_orders_dataset.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# 2. olist_order_reviews_dataset.csv ê²€ì¦
print("[2/5] ë¦¬ë·° ë°ì´í„° ê²€ì¦ ì¤‘...")
reviews_file = os.path.join(PROCESSED_PATH, "proc_olist_order_reviews_dataset.csv")
if os.path.exists(reviews_file):
    reviews = pd.read_csv(reviews_file)
    check(reviews['review_comment_message'].isnull().sum() == 0, "  - ë¦¬ë·° ë©”ì‹œì§€ ê²°ì¸¡ì¹˜ ë³´ì • ì™„ë£Œ (ë¹ˆ ë¬¸ìì—´)", "  - ë¦¬ë·° ë©”ì‹œì§€ì— Null ê°’ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    check(reviews.duplicated(subset='order_id').sum() == 0, "  - ì£¼ë¬¸ë‹¹ ì¤‘ë³µ ë¦¬ë·° ì œê±° ì™„ë£Œ", "  - ì£¼ë¬¸ë‹¹ ì¤‘ë³µëœ ë¦¬ë·°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
else:
    errors.append("proc_olist_order_reviews_dataset.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# 3. olist_products_dataset.csv ê²€ì¦ (í•œê¸€ ë§¤í•‘ í•µì‹¬)
print("[3/5] ìƒí’ˆ ë°ì´í„° ê²€ì¦ ì¤‘...")
products_file = os.path.join(PROCESSED_PATH, "proc_olist_products_dataset.csv")
if os.path.exists(products_file):
    products = pd.read_csv(products_file)
    check('product_category_name_english' in products.columns, "  - ì˜ë¬¸ ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ ì¡´ì¬", "  - ì˜ë¬¸ ë§¤í•‘ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    check('product_category_name_korean' in products.columns, "  - í•œê¸€ ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ ì¡´ì¬", "  - í•œê¸€ ë§¤í•‘ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    check(products['product_category_name_korean'].isnull().sum() == 0, "  - í•œê¸€ ì¹´í…Œê³ ë¦¬ ê²°ì¸¡ì¹˜ ë³´ì • ì™„ë£Œ", "  - í•œê¸€ ì¹´í…Œê³ ë¦¬ì— Null ê°’ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    check('ê¸°íƒ€' in products['product_category_name_korean'].values, "  - í•œê¸€ ì¹´í…Œê³ ë¦¬ 'ê¸°íƒ€' í”Œë˜ê·¸ í™•ì¸", "  - í•œê¸€ ì¹´í…Œê³ ë¦¬ì— 'ê¸°íƒ€' ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    errors.append("proc_olist_products_dataset.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# 4. olist_geolocation_dataset.csv ê²€ì¦ (í•œê¸€ ì£¼ ëª…ì¹­)
print("[4/5] ìœ„ì¹˜ ì •ë³´ ë°ì´í„° ê²€ì¦ ì¤‘...")
geo_file = os.path.join(PROCESSED_PATH, "proc_olist_geolocation_dataset.csv")
if os.path.exists(geo_file):
    geo = pd.read_csv(geo_file, dtype={'geolocation_zip_code_prefix': str})
    check(geo['geolocation_zip_code_prefix'].str.contains('^0').any() if any(geo['geolocation_zip_code_prefix'].str.startswith('0')) else True, 
          "  - ìš°í¸ë²ˆí˜¸ ì•ìë¦¬ '0' ë³´ì¡´ í™•ì¸ (ë¬¸ìì—´ íƒ€ì…)", "  - ìš°í¸ë²ˆí˜¸ ë°ì´í„° íƒ€ì… ì˜¤ë¥˜ (ìˆ«ìë¡œ ì¸ì‹ë˜ì–´ 0 ìœ ì‹¤ ê°€ëŠ¥ì„±)")
    check('geolocation_state_korean' in geo.columns, "  - í•œê¸€ ì£¼(State) ëª…ì¹­ ì»¬ëŸ¼ ì¡´ì¬", "  - geolocation_state_korean ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    check(geo.duplicated(subset='geolocation_zip_code_prefix').sum() == 0, "  - ìš°í¸ë²ˆí˜¸ ê¸°ì¤€ ì¤‘ë³µ ì œê±° ì™„ë£Œ", "  - ìš°í¸ë²ˆí˜¸ê°€ ì¤‘ë³µëœ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
else:
    errors.append("proc_olist_geolocation_dataset.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# 5. olist_customers_dataset.csv / olist_sellers_dataset.csv ê²€ì¦
print("[5/5] ê³ ê°/íŒë§¤ì ë°ì´í„° ê²€ì¦ ì¤‘...")
cust_file = os.path.join(PROCESSED_PATH, "proc_olist_customers_dataset.csv")
if os.path.exists(cust_file):
    customers = pd.read_csv(cust_file)
    check('customer_state_korean' in customers.columns, "  - ê³ ê° ë°ì´í„° í•œê¸€ ì£¼ ëª…ì¹­ ì¶”ê°€ í™•ì¸", "  - customer_state_korean ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

sell_file = os.path.join(PROCESSED_PATH, "proc_olist_sellers_dataset.csv")
if os.path.exists(sell_file):
    sellers = pd.read_csv(sell_file)
    check('seller_state_korean' in sellers.columns, "  - íŒë§¤ì ë°ì´í„° í•œê¸€ ì£¼ ëª…ì¹­ ì¶”ê°€ í™•ì¸", "  - seller_state_korean ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ìµœì¢… ê²°ê³¼ ì¶œë ¥
print("\n" + "="*50)
if not errors:
    print("âœ¨ ê²€ì¦ ê²°ê³¼: ëª¨ë“  ì „ì²˜ë¦¬ í•­ëª©ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! (V1.1 í•©ê²©)")
else:
    print(f"âš ï¸ ê²€ì¦ ê²°ê³¼: {len(errors)}ê°œì˜ í•­ëª©ì—ì„œ ì˜¤ë¥˜/ëˆ„ë½ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    for e in errors:
        print(f"  âŒ {e}")
print("="*50)
